# Image Dehazing using Deep Learning

## LC Net

**By:**  
Pratham Shah - IU1941230155  
Manit Shah - IU1941230150

**Mentor:**  
Dr. Kaushal Jani

---

## Table of Contents

1. [Aim](#aim)  
2. [Dataset](#dataset)  
3. [Model](#model)  
4. [Packages & Libraries](#packages-libraries)  
5. [Steps](#steps)  
6. [Applications](#applications)

---

## Aim

The aim of our project is to dehaze hazy images.  
Image dehazing is a crucial image pre-processing task aimed at removing the incoherent noise generated by haze to improve the visual appeal of the image.

We input a hazy image and expect to produce a clear (dehazed) image.

---

## Dataset

REalistic Single Image DEhazing (RESIDE) is a large-scale benchmark consisting of both synthetic and real-world hazy images useful for a comprehensive study and evaluation of existing single image dehazing algorithms.

RESIDE highlights diverse data sources and image contents, and is divided into five subsets, each serving different training or evaluation purposes. RESIDE-Standard's Synthetic Objective Testing Set (SOTS) consists of indoor and outdoor subsets of clear and hazy images.

**The dataset is available at:**  
[RESIDE Dataset on Kaggle](https://www.kaggle.com/datasets/balraj98/synthetic-objective-testing-set-sots-reside)

**Another dataset used:**  
[Car Plate Detection Dataset](https://www.kaggle.com/datasets/andrewmvd/car-plate-detection)

---

## Model

The existing models use sophisticated networks and custom loss functions which are computationally inefficient and require heavy hardware to run. LC Net achieves optimum dehazing performance at a much faster rate, on several standard datasets, comparable to the state-of-the-art methods in terms of image quality.

### LC Net (Light Convolutional Network)

LC Net is a very light convolutional encoder-decoder network that does not depend on any atmospheric models.

---

### Architecture

This neural network consists of an encoder-decoder type of architecture.

- The input layer takes an image, which is padded and pushed to the first ReLU-activated convolutional layer with 50 filters of size 3.
- The result is passed to the average pooling layer for downsampling (factor of 2), followed by another convolutional layer, repeating the cycle.
- This forms an encoded input, which is then passed through two fully connected ReLU-activated dense layers with 10 neurons each.
- The decoder consists of two pairs of deconvolutional and upsampling layers (scale factor of 2).
- The final output layer is a deconvolutional layer with three filters of size 3, producing a dehazed image of the same size as the input image.

---
<img width="926" alt="image" src="https://github.com/user-attachments/assets/b6269f93-414f-45b7-a4b9-d8220afc6f15">



## Packages & Libraries

1. TensorFlow  
2. Pillow  
3. Streamlit  
4. Matplotlib  
5. Numpy  

---

## Steps

1. Gathering Data  
2. Preprocessing Data  
3. Training the Model  
4. Applying Model to Predict Output  
5. Developing UI and Connecting it with the Model  

---

## Output

---

## Thank You
